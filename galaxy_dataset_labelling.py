# -*- coding: utf-8 -*-
"""galaxy_dataset_labelling.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OG9GQZZiz3fanaV0yMnyZNNtLx9MIPbs
"""

from google.colab import drive
drive.mount('/content/drive')

"""# **Install library for kaggle**"""

!pip install kaggle

!pip install google-colab

"""# **input the json file which got from kaggle account**"""

from google.colab import files

# Upload your Kaggle API key file
uploaded = files.upload()

# Move the uploaded file to the required directory
!mkdir -p ~/.kaggle
!mv kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

"""# **Download the data set from kaggle to co lab**"""

!kaggle competitions download -c galaxy-zoo-the-galaxy-challenge

"""# **unzip the data set**"""

!unzip /content/galaxy-zoo-the-galaxy-challenge.zip

"""# **unzip the subfolder which contains the images**"""

!unzip /content/images_training_rev1.zip

"""# **Importing necessary libraries**"""

import pandas as pd
import os
import shutil
import zipfile

"""# **input the csv file which contain the details**"""

df = pd.read_csv('/content/galaxy_data.csv')
# Display the DataFrame
df.head()

"""# **remove the columns except first 4**"""

df_cleaned = df.iloc[:, 0:4]

# Display the cleaned DataFrame
print(df_cleaned)

df_cleaned.head()

# Check the column names in your DataFrame
print(df_cleaned.columns)

# Count values greater than 0.9 in each column
greater_than_09_count = (df_cleaned > 0.9).sum()

# Display the count
print("Number of values greater than 0.9 in each column:")
print(greater_than_09_count)

"""# **remove the column star due to low number count**"""

df1=df_cleaned.drop(columns=['star'])

# Display the modified DataFrame
print(df1)

"""# **drop disk column and save to df2**"""

df2=df1.drop(columns=['disk'])

# Display the modified DataFrame
print(df2)

"""# **drop smooth column and save to df3**"""

df3=df1.drop(columns=['smooth'])

# Display the modified DataFrame
print(df3)

"""# **change the values to 1 if its above 0.9 other wise set it to 0 for smooth column**"""

# Iterate over columns starting from the second column
for col in df2.columns[1:]:
    df2[col] = df2[col].apply(lambda x: 1 if x > 0.9 else 0)

# Display the modified DataFrame
print(df2)

"""# **change the values to 1 if its above 0.9 other wise set it to 0 for disk column**"""

# Iterate over columns starting from the second column
for col in df3.columns[1:]:
    df3[col] = df3[col].apply(lambda x: 1 if x > 0.9 else 0)

# Display the modified DataFrame
print(df3)

"""# **create df_new with df2**"""

df_new= df2
# Display the modified DataFrame
print(df_new)

"""# **add df3 in df_new**"""

df_new['disk'] = df3['disk']
# Display the modified DataFrame
print(df_new)

df_new

"""# **check any columns in same raw have 2 ones**"""

# Sum the values of the three columns
df_new['sum'] = df_new['smooth'] + df_new['disk']

# Count rows where the sum is greater than 1
count_greater_than_1 = (df_new['sum'] > 1).sum()

# Display the count
print("Number of rows where the sum is greater than 1 is ", count_greater_than_1)

"""# **remove raws with both 0 and 0**"""

# Filter out rows where the value in the 'sum' column is not equal to 0
df_new = df_new[df_new['sum'] != 0]

# Display the modified DataFrame
print(df_new)

"""# **remove column sum**"""

df_new.drop(columns=['sum'], inplace=True)

# Display the modified DataFrame
print(df_new)

"""# **save df as a csv file**"""

# Save the DataFrame to a CSV file
df_new.to_csv('output.csv', index=False)

# Optionally, if you're using Google Colab and want to download the file directly
from google.colab import files
files.download('output.csv')

!mkdir sorted_data
!mkdir sorted_data/smooth
!mkdir sorted_data/disk

#!rm -rf sorted_data

"""# **split data  according to the csv file**"""

# Define paths to your CSV file and image directory
csv_file = '/content/output.csv'
image_dir = '/content/images_training_rev1'
smooth_folder = '/content/sorted_data/smooth'
disk_folder = '/content/sorted_data/disk'

# Read the CSV file
df = pd.read_csv(csv_file)

# Iterate over each row in the DataFrame
for index, row in df.iterrows():
    image_id = row['id']
    smooth_label = row['smooth']
    disk_label = row['disk']

    # Check if smooth label is 1 and move the image to the smooth folder
    if smooth_label == 1:
        source_path = os.path.join(image_dir, f'{image_id}.jpg')
        destination_path = os.path.join(smooth_folder, f'{image_id}.jpg')
        shutil.move(source_path, destination_path)
        print(f"Moved image {image_id}.jpg to smooth folder")

    # Check if disk label is 1 and move the image to the disk folder
    if disk_label == 1:
        source_path = os.path.join(image_dir, f'{image_id}.jpg')
        destination_path = os.path.join(disk_folder, f'{image_id}.jpg')
        shutil.move(source_path, destination_path)
        print(f"Moved image {image_id}.jpg to disk folder")

"""# **count file in smooth**"""

# Define the path to the directory
directory_path = '/content/sorted_data/smooth'

# Function to count files in a directory recursively
def count_files(directory):
    total_files = 0
    # Walk through all directories and files in the directory
    for root, dirs, files in os.walk(directory):
        # Add the number of files in the current directory
        total_files += len(files)
    return total_files

# Count files in the directory
num_files = count_files(directory_path)

# Print the total number of files
print("Total number of files in subfolders:", num_files)

"""# **count files in disk**"""

# Define the path to the directory
directory_path = '/content/sorted_data/disk'

# Function to count files in a directory recursively
def count_files(directory):
    total_files = 0
    # Walk through all directories and files in the directory
    for root, dirs, files in os.walk(directory):
        # Add the number of files in the current directory
        total_files += len(files)
    return total_files

# Count files in the directory
num_files = count_files(directory_path)

# Print the total number of files
print("Total number of files in subfolders:", num_files)

"""# **compress the data set**"""

# Define the folder to compress
folder_to_compress = '/content/sorted_data'

# Define the path for the output ZIP file
output_zip_path = '/content/drive/My Drive/sorted_data.zip'

# Create a ZIP file
with zipfile.ZipFile(output_zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
    # Walk through all directories and files in the folder
    for root, dirs, files in os.walk(folder_to_compress):
        # Add each file to the ZIP file
        for file in files:
            file_path = os.path.join(root, file)
            zipf.write(file_path, os.path.relpath(file_path, folder_to_compress))

print("Folder compressed successfully.")



