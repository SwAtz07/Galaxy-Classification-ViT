# -*- coding: utf-8 -*-
"""new_vit (2).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pjuYiyrJKoq_eYv8uZ9KiXNNGWUpv6GC

# **Connecting to Google drive for Data**
"""

from google.colab import drive
drive.mount('/content/drive')

"""# **Copy data drom google drive**"""

!cp /content/drive/MyDrive/sorted_data.zip /content

"""# **Extracting the zip file**"""

!unzip /content/sorted_data.zip

"""# **Using for image Augmentation**"""

!pip install Augmentor

"""# **Generating and saving 12k of Smooth galaxy images to aug_smooth**"""

import os
import Augmentor

def augment_images(input_folder, output_folder, num_images):
    # Initialize an Augmentor pipeline
    p = Augmentor.Pipeline(input_folder, output_folder)

    # Add augmentation operations to the pipeline
    p.rotate(probability=0.7, max_left_rotation=10, max_right_rotation=10)
    p.flip_left_right(probability=0.5)
    p.flip_top_bottom(probability=0.5)
    p.zoom_random(probability=0.5, percentage_area=0.8)
    p.random_distortion(probability=0.5, grid_width=4, grid_height=4, magnitude=8)

    # Set the number of augmented images to generate
    p.sample(num_images)

if __name__ == "__main__":
    input_folder = "/content/smooth"
    output_folder = "/content/aug_smooth"
    num_images = 12000  # Number of augmented images to generate

    # Create the output folder if it doesn't exist
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    augment_images(input_folder, output_folder, num_images)

"""# **Generating and saving 12k of disk galaxy images to aug_dissk**"""

def augment_images(input_folder, output_folder, num_images):
    # Initialize an Augmentor pipeline
    p = Augmentor.Pipeline(input_folder, output_folder)

    # Add augmentation operations to the pipeline
    p.rotate(probability=0.7, max_left_rotation=10, max_right_rotation=10)
    p.flip_left_right(probability=0.5)
    p.flip_top_bottom(probability=0.5)
    p.zoom_random(probability=0.5, percentage_area=0.8)
    p.random_distortion(probability=0.5, grid_width=4, grid_height=4, magnitude=8)

    # Set the number of augmented images to generate
    p.sample(num_images)

if __name__ == "__main__":
    input_folder = "/content/disk"
    output_folder = "/content/aug_disk"
    num_images = 12000  # Number of augmented images to generate

    # Create the output folder if it doesn't exist
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    augment_images(input_folder, output_folder, num_images)

"""# **Creating new folder for Data and moving both folders**"""

!mkdir data
!mv /content/aug_smooth /content/data
!mv /content/aug_disk /content/data

"""# **Counting the number of images in Folder Data**"""

import os
def count_files_in_subfolders(folder_path):
    for root, dirs, files in os.walk(folder_path):
        total_files = len(files)
        print(f"Number of files in '{root}': {total_files}")

folder_path = "/content/data"
count_files_in_subfolders(folder_path)

"""# **library to split data in to train,validation and test**"""

!pip install split-folders

"""# **Spliting Data in to a new folder data-Splitted**"""

import splitfolders
path = "/content/data"
#print(os.listdir(path))
splitfolders.ratio(path,seed=1337, output="data-Splitted", ratio=(0.80, 0.15, 0.05))

"""# **Counting the number of images in each folders**"""

def count_files_in_subfolders(folder_path):
    for root, dirs, files in os.walk(folder_path):
        total_files = len(files)
        print(f"Number of files in '{root}': {total_files}")


count_files_in_subfolders("/content/data-Splitted/train")
count_files_in_subfolders("/content/data-Splitted/val")
count_files_in_subfolders("/content/data-Splitted/test")

import torch
from torch import nn
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
from transformers import ViTForImageClassification, ViTImageProcessor
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt
import numpy as np

"""# Data preprocessing and loading"""

data_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),  # Converts to a tensor with pixel values between 0 and 1
])

dataset = datasets.ImageFolder(root='/content/data-Splitted/train', transform=data_transform)
train_loader = DataLoader(dataset, batch_size=32, shuffle=True)

val_dataset = datasets.ImageFolder(root='/content/data-Splitted/val', transform=data_transform)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)

"""# Load the ViT model and feature extractor"""

feature_extractor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224-in21k', do_rescale=False)
model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224-in21k', num_labels=2)

"""# Training setup"""

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)
optimizer = torch.optim.Adam(model.parameters(), lr=5e-5)
loss_fn = nn.CrossEntropyLoss()
num_epochs = 5
train_losses = []
val_losses = []

"""# **Model Trainning in Galaxy classsification Dataset**"""

import time
# Start time
start_time = time.time()

for epoch in range(num_epochs):
    # Training loop
    model.train()
    running_train_loss = 0.0
    for batch in train_loader:
        images, labels = batch
        images = feature_extractor(images, return_tensors="pt").pixel_values.to(device)
        labels = labels.to(device)

        outputs = model(images)
        loss = loss_fn(outputs.logits, labels)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        running_train_loss += loss.item()
    avg_train_loss = running_train_loss / len(train_loader)
    train_losses.append(avg_train_loss)

    # Validation loop
    model.eval()
    running_val_loss = 0.0
    with torch.no_grad():
        for batch in val_loader:
            images, labels = batch
            images = feature_extractor(images, return_tensors="pt").pixel_values.to(device)
            labels = labels.to(device)

            outputs = model(images)
            loss = loss_fn(outputs.logits, labels)
            running_val_loss += loss.item()
    avg_val_loss = running_val_loss / len(val_loader)
    val_losses.append(avg_val_loss)

    print(f"Epoch {epoch+1}/{num_epochs} - Train Loss: {avg_train_loss:.4f} - Val Loss: {avg_val_loss:.4f}")

# End time
end_time = time.time()
# Duration calculation
duration = end_time - start_time
# Displaying the duration
print("Total Duration of the trainning process is : {} seconds".format(int(duration)))

"""# Plot training and validation loss"""

plt.figure()
plt.plot(range(1, num_epochs + 1), train_losses, label='Training Loss')
plt.plot(range(1, num_epochs + 1), val_losses, label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.title('Training and Validation Loss')
plt.show()

"""# Evaluation and Confusion Matrix"""

model.eval()
all_labels = []
all_preds = []
with torch.no_grad():
    for batch in val_loader:
        images, labels = batch
        images = feature_extractor(images, return_tensors="pt").pixel_values.to(device)
        labels = labels.to(device)
        outputs = model(images)
        _, predicted = torch.max(outputs.logits, 1)
        all_labels.extend(labels.cpu().numpy())
        all_preds.extend(predicted.cpu().numpy())

# Compute confusion matrix
cm = confusion_matrix(all_labels, all_preds)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=dataset.classes)

# Plot confusion matrix
disp.plot(cmap=plt.cm.Blues)
plt.show()

"""# accuracy"""

accuracy = np.sum(np.array(all_preds) == np.array(all_labels)) / len(all_labels)
print(f'Accuracy: {accuracy * 100:.2f}%')

"""# Test data"""

dataset = datasets.ImageFolder(root='/content/data-Splitted/test', transform=data_transform)
test_loader = DataLoader(dataset, batch_size=32, shuffle=True)

model.eval()
all_labels = []
all_preds = []
with torch.no_grad():

    for batch in test_loader:
        images, labels = batch
        images = feature_extractor(images, return_tensors="pt").pixel_values.to(device)
        labels = labels.to(device)
        outputs = model(images)
        _, predicted = torch.max(outputs.logits, 1)
        all_labels.extend(labels.cpu().numpy())
        all_preds.extend(predicted.cpu().numpy())

labels

predicted